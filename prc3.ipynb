{"cells":[{"cell_type":"code","source":["#google ->spark.apache.org ->documentation ->lateset release ->Api docs ->pyhon ->getting started ->qucik start :DataFrame\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Practical no : 3 (Using Pyspark DataFrames )","showTitle":true,"inputWidgets":{},"nuid":"445b064f-6665-4cea-af7d-10b076e294a5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"683b529d-3b35-47c8-a915-227b10aef86d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from datetime import datetime, date\nimport pandas as pd\nfrom pyspark.sql import Row"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"DataFrame Creation","showTitle":true,"inputWidgets":{},"nuid":"e9fccc75-6191-47e6-9fd5-f812b6e24acc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.createDataFrame([\n    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n])\ndf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76bcc40e-b1d9-4a40-bffb-df6087047c87"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[4]: DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[4]: DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"]}}],"execution_count":0},{"cell_type":"code","source":["df = spark.createDataFrame([\n    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n], schema='a long, b double, c string, d date, e timestamp')\ndf\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Create a PySpark DataFrame with an explicit schema.","showTitle":true,"inputWidgets":{},"nuid":"6fdbf749-c3df-41c6-b410-e7867bf6020a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[5]: DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[5]: DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"]}}],"execution_count":0},{"cell_type":"code","source":["pandas_df = pd.DataFrame({\n    'a': [1, 2, 3],\n    'b': [2., 3., 4.],\n    'c': ['string1', 'string2', 'string3'],\n    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n})\ndf = spark.createDataFrame(pandas_df)\ndf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Create a PySpark DataFrame from a pandas DataFrame","showTitle":true,"inputWidgets":{},"nuid":"d3d8cb79-89ec-4d7f-9af5-9d8fcc4e4e3c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[6]: DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[6]: DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"]}}],"execution_count":0},{"cell_type":"code","source":["rdd = spark.sparkContext.parallelize([\n    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n])\ndf = spark.createDataFrame(rdd, schema=['a', 'b', 'c', 'd', 'e'])\ndf\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Create a PySpark DataFrame from an RDD consisting of a list of tuples.","showTitle":true,"inputWidgets":{},"nuid":"e2cc0c3c-8fe5-47be-b43e-4aac3995d3ea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[7]: DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[7]: DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"]}}],"execution_count":0},{"cell_type":"code","source":["# All DataFrames above result same.\ndf.show()\ndf.printSchema()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"The DataFrames created above all have the same results and schema.","showTitle":true,"inputWidgets":{},"nuid":"0f231352-e259-4128-8ebc-8d0bda6c8505"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+---+-------+----------+-------------------+\n|  a|  b|      c|         d|                  e|\n+---+---+-------+----------+-------------------+\n|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n+---+---+-------+----------+-------------------+\n\nroot\n |-- a: long (nullable = true)\n |-- b: double (nullable = true)\n |-- c: string (nullable = true)\n |-- d: date (nullable = true)\n |-- e: timestamp (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+---+-------+----------+-------------------+\n|  a|  b|      c|         d|                  e|\n+---+---+-------+----------+-------------------+\n|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n+---+---+-------+----------+-------------------+\n\nroot\n |-- a: long (nullable = true)\n |-- b: double (nullable = true)\n |-- c: string (nullable = true)\n |-- d: date (nullable = true)\n |-- e: timestamp (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#The top rows of a DataFrame can be displayed using DataFrame.show().\n\ndf.show(1)\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Viewing Data","showTitle":true,"inputWidgets":{},"nuid":"3f6e042e-7b0a-411f-b12a-545f3d814420"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+---+-------+----------+-------------------+\n|  a|  b|      c|         d|                  e|\n+---+---+-------+----------+-------------------+\n|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n+---+---+-------+----------+-------------------+\nonly showing top 1 row\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+---+-------+----------+-------------------+\n|  a|  b|      c|         d|                  e|\n+---+---+-------+----------+-------------------+\n|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n+---+---+-------+----------+-------------------+\nonly showing top 1 row\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"You can see the DataFrameâ€™s schema and column names as follows:","showTitle":true,"inputWidgets":{},"nuid":"28d63c9d-a1af-4f65-96b2-5c3b0c83a415"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[10]: ['a', 'b', 'c', 'd', 'e']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[10]: ['a', 'b', 'c', 'd', 'e']"]}}],"execution_count":0},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"323aa712-c4e3-41a8-a9a6-963f5b8e0133"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- a: long (nullable = true)\n |-- b: double (nullable = true)\n |-- c: string (nullable = true)\n |-- d: date (nullable = true)\n |-- e: timestamp (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- a: long (nullable = true)\n |-- b: double (nullable = true)\n |-- c: string (nullable = true)\n |-- d: date (nullable = true)\n |-- e: timestamp (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(\"a\", \"b\", \"c\").describe().show()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Show the summary of the DataFrame","showTitle":true,"inputWidgets":{},"nuid":"61e60482-94da-4f0d-a2cf-d91f67408f2e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+---+---+-------+\n|summary|  a|  b|      c|\n+-------+---+---+-------+\n|  count|  3|  3|      3|\n|   mean|2.0|3.0|   null|\n| stddev|1.0|1.0|   null|\n|    min|  1|2.0|string1|\n|    max|  3|4.0|string3|\n+-------+---+---+-------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+---+---+-------+\n|summary|  a|  b|      c|\n+-------+---+---+-------+\n|  count|  3|  3|      3|\n|   mean|2.0|3.0|   null|\n| stddev|1.0|1.0|   null|\n|    min|  1|2.0|string1|\n|    max|  3|4.0|string3|\n+-------+---+---+-------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.collect()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"collects the distributed data to the driver side as the local data in Python. ","showTitle":true,"inputWidgets":{},"nuid":"54d54bea-f8a8-4f13-a9a5-4a29e6d50673"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[13]: [Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0)),\n Row(a=2, b=3.0, c='string2', d=datetime.date(2000, 2, 1), e=datetime.datetime(2000, 1, 2, 12, 0)),\n Row(a=3, b=4.0, c='string3', d=datetime.date(2000, 3, 1), e=datetime.datetime(2000, 1, 3, 12, 0))]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[13]: [Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0)),\n Row(a=2, b=3.0, c='string2', d=datetime.date(2000, 2, 1), e=datetime.datetime(2000, 1, 2, 12, 0)),\n Row(a=3, b=4.0, c='string3', d=datetime.date(2000, 3, 1), e=datetime.datetime(2000, 1, 3, 12, 0))]"]}}],"execution_count":0},{"cell_type":"code","source":["df.take(1)\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"In order to avoid throwing an out-of-memory exception, use DataFrame.take() or DataFrame.tail().","showTitle":true,"inputWidgets":{},"nuid":"c6b21609-d109-47ed-a3ab-369de41db914"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[14]: [Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0))]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[14]: [Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0))]"]}}],"execution_count":0},{"cell_type":"code","source":["df.toPandas()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"PySpark DataFrame also provides the conversion back to a pandas DataFrame to leverage pandas API.","showTitle":true,"inputWidgets":{},"nuid":"ef6f0932-d4a3-4297-b942-9cf01a267ff1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n      <th>d</th>\n      <th>e</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>string1</td>\n      <td>2000-01-01</td>\n      <td>2000-01-01 12:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3.0</td>\n      <td>string2</td>\n      <td>2000-02-01</td>\n      <td>2000-01-02 12:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.0</td>\n      <td>string3</td>\n      <td>2000-03-01</td>\n      <td>2000-01-03 12:00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n      <th>d</th>\n      <th>e</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2.0</td>\n      <td>string1</td>\n      <td>2000-01-01</td>\n      <td>2000-01-01 12:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3.0</td>\n      <td>string2</td>\n      <td>2000-02-01</td>\n      <td>2000-01-02 12:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.0</td>\n      <td>string3</td>\n      <td>2000-03-01</td>\n      <td>2000-01-03 12:00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df.a"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Selecting and Accessing Data","showTitle":true,"inputWidgets":{},"nuid":"0339ee73-26f3-4334-b824-d7387267e323"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[16]: Column<'a'>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[16]: Column<'a'>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import Column\nfrom pyspark.sql.functions import upper\n\ntype(df.c) == type(upper(df.c)) == type(df.c.isNull())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"# checking column value types","showTitle":true,"inputWidgets":{},"nuid":"90dcac63-9d7e-4975-a9ac-2f0ac640c9c3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[17]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[17]: True"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(df.c).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bae6df82-41f9-42b3-b55d-837467e6c16d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+\n|      c|\n+-------+\n|string1|\n|string2|\n|string3|\n+-------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+\n|      c|\n+-------+\n|string1|\n|string2|\n|string3|\n+-------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["type(df.a)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3f90649-adfb-4610-998a-664bda00fc8c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[19]: pyspark.sql.column.Column","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[19]: pyspark.sql.column.Column"]}}],"execution_count":0},{"cell_type":"code","source":["type(upper(df.a))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"136cd71f-9817-492b-a00c-4556bbafa921"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[20]: pyspark.sql.column.Column","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[20]: pyspark.sql.column.Column"]}}],"execution_count":0},{"cell_type":"code","source":["type(df.a.isNull())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3aae63be-09f0-4ffd-853d-f8235ddbfe67"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[21]: pyspark.sql.column.Column","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[21]: pyspark.sql.column.Column"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(df.b).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c705af3e-ef74-4a88-aedc-5e78d625e810"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+\n|  b|\n+---+\n|2.0|\n|3.0|\n|4.0|\n+---+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+\n|  b|\n+---+\n|2.0|\n|3.0|\n|4.0|\n+---+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.withColumn('upper_c', upper(df.c)).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"add new column in data frame  (Assign new Column instance.)","showTitle":true,"inputWidgets":{},"nuid":"768f8c10-c69c-4335-9e54-96aa17492a4b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+---+-------+----------+-------------------+-------+\n|  a|  b|      c|         d|                  e|upper_c|\n+---+---+-------+----------+-------------------+-------+\n|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|STRING1|\n|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|STRING2|\n|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|STRING3|\n+---+---+-------+----------+-------------------+-------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+---+-------+----------+-------------------+-------+\n|  a|  b|      c|         d|                  e|upper_c|\n+---+---+-------+----------+-------------------+-------+\n|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|STRING1|\n|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|STRING2|\n|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|STRING3|\n+---+---+-------+----------+-------------------+-------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.filter(df.a == 3).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"To select a subset of rows, use DataFrame.filter().","showTitle":true,"inputWidgets":{},"nuid":"9b4777fd-5175-4d85-a7e8-6f67248db47b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+---+-------+----------+-------------------+\n|  a|  b|      c|         d|                  e|\n+---+---+-------+----------+-------------------+\n|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n+---+---+-------+----------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+---+-------+----------+-------------------+\n|  a|  b|      c|         d|                  e|\n+---+---+-------+----------+-------------------+\n|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n+---+---+-------+----------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.filter(df.c == 'string2').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"To select a subset of rows, use DataFrame.filter().","showTitle":true,"inputWidgets":{},"nuid":"60ba1684-bf8a-4aab-b16d-39aeb35f6356"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+---+-------+----------+-------------------+\n|  a|  b|      c|         d|                  e|\n+---+---+-------+----------+-------------------+\n|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n+---+---+-------+----------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+---+-------+----------+-------------------+\n|  a|  b|      c|         d|                  e|\n+---+---+-------+----------+-------------------+\n|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n+---+---+-------+----------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nfrom pyspark.sql.functions import pandas_udf\n\n@pandas_udf('long')\ndef pandas_plus_one(series: pd.Series) -> pd.Series:\n    # Simply plus one by using pandas Series.\n    return series + 1\n\ndf.select(pandas_plus_one(df.a)).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Applying a Function","showTitle":true,"inputWidgets":{},"nuid":"4abd1f1e-daeb-46ff-9eb8-b1d28cc8e724"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------------------+\n|pandas_plus_one(a)|\n+------------------+\n|                 2|\n|                 3|\n|                 4|\n+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------------------+\n|pandas_plus_one(a)|\n+------------------+\n|                 2|\n|                 3|\n|                 4|\n+------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9426c3e5-2372-4757-9e14-296e6ae92aa3"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"prc3","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2499135030605200}},"nbformat":4,"nbformat_minor":0}
